{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd0192b2adcf89bab941b7e96bafb904814dc6d17ff788fb22c8b7040cb8680f0f5",
   "display_name": "Python 3.7.3 64-bit ('cs224w': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import LongformerTokenizerFast, LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from preprocess import preprocess_data, get_dataset_and_labels\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 256\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096', max_length = max_sequence_length)\n",
    "model = LongformerForSequenceClassification.from_pretrained('./results/twitter-rumour-classification/', local_files_only=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label == \"rumour\":\n",
    "        return 1\n",
    "    elif label == \"non-rumour\":\n",
    "        return 0\n",
    "    else:\n",
    "        raise Exception(\"label classes must be 'rumour' or 'non-rumour'\")\n",
    "\n",
    "\n",
    "def convert_label_to_rumour(label):\n",
    "    if label == 1:\n",
    "        return \"rumour\"\n",
    "    elif label == 0:\n",
    "        return \"non-rumour\"\n",
    "    else:\n",
    "        raise Exception(\"label classes must be 1 or 0\")\n",
    "\n",
    "\n",
    "def get_labels(label_path, sourceIds):\n",
    "    with open(label_path) as f:\n",
    "        labels = json.load(f)\n",
    "    corresponding_labels = [labels[id] for id in sourceIds]\n",
    "    numeric_labels = [convert_label(label) for label in corresponding_labels]\n",
    "\n",
    "    return numeric_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./project_data/test.data.jsonl\"\n",
    "test_texts, sourceIds = preprocess_data(data_path=test_path, max_sequence_length=max_sequence_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(test_texts, padding = 'max_length', truncation=True, max_length = max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset:\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.tokenized_texts.items()}\n",
    "\n",
    "test_dataset = TestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 73/73 [00:11<00:00,  6.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "label_ids: torch.Tensor = None\n",
    "preds: torch.Tensor = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "\n",
    "        batch['input_ids'] = batch['input_ids'].cuda()\n",
    "            \n",
    "        predictions = model(input_ids=batch['input_ids']\n",
    "                                   )\n",
    "        \n",
    "        predictions = predictions[0]\n",
    "\n",
    "        if preds is None:\n",
    "            preds = predictions.detach().sigmoid()\n",
    "        else:\n",
    "            preds = torch.cat((preds, predictions.detach()), dim=0)\n",
    "\n",
    "\n",
    "        # if label_ids is None:\n",
    "        #     label_ids = batch[\"labels\"].detach()\n",
    "        # else:\n",
    "        #     label_ids = torch.cat((label_ids, batch[\"labels\"].detach()), dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(preds.to(\"cpu\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {sourceId: convert_label_to_rumour(prediction) for sourceId, prediction in zip(sourceIds, predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-output.json\", \"w\") as outputfile:\n",
    "    json.dump(predictions_dict, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_path = './project_data/dev.data.jsonl'\n",
    "val_labels_path = './project_data/dev.label.json'\n",
    "\n",
    "val_texts, val_sourceIds = preprocess_data(data_path=data_val_path, max_sequence_length=max_sequence_length)\n",
    "val_labels = get_labels(val_labels_path, val_sourceIds)\n",
    "val_encodings = tokenizer(val_texts, padding = 'max_length', truncation=True, max_length = max_sequence_length)\n",
    "val_dataset = TestDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 73/73 [00:10<00:00,  6.95it/s]\n"
     ]
    }
   ],
   "source": [
    "label_ids: torch.Tensor = None\n",
    "val_preds: torch.Tensor = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "\n",
    "        batch['input_ids'] = batch['input_ids'].cuda()\n",
    "            \n",
    "        val_predictions = model(input_ids=batch['input_ids']\n",
    "                                   )\n",
    "        \n",
    "        val_predictions = val_predictions[0]\n",
    "\n",
    "        if val_preds is None:\n",
    "            val_preds = val_predictions.detach().sigmoid()\n",
    "        else:\n",
    "            val_preds = torch.cat((val_preds, val_predictions.detach()), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "val_predictions = np.argmax(val_preds.to(\"cpu\"), axis=1)\n",
    "p, r, f, _ = precision_recall_fscore_support(val_predictions, val_labels, pos_label=1, average=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision:  0.7967914438502673\nRecall:  0.8713450292397661\nF1:  0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", p)\n",
    "print(\"Recall: \", r)\n",
    "print(\"F1: \", f)"
   ]
  }
 ]
}