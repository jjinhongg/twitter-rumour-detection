{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f646959e",
   "metadata": {},
   "source": [
    "# COVID-19 Tweet Predictions\n",
    "\n",
    "This notebook is designed to perform predictions on COVID-19 related tweets. \n",
    "The goal is to classify the sentiment or topic of each tweet using pre-trained machine learning models.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Installing Required Packages\n",
    "2. Environment Setup\n",
    "3. Data Loading\n",
    "4. Model Inference\n",
    "5. Results and Analysis\n",
    "\n",
    "## How to Run\n",
    "\n",
    "To execute the notebook, simply run each cell in order. \n",
    "If running on Google Colab, make sure to mount your Google Drive if necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec7bdc",
   "metadata": {},
   "source": [
    "## Installing Required Packages\n",
    "\n",
    "The following packages are essential for running the analyses in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17779,
     "status": "ok",
     "timestamp": 1620899427693,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "RRJhq5no1cyV",
    "outputId": "61c84818-3561-4718-a202-34f88d339c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install tweet-preprocessor\n",
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd8b51",
   "metadata": {},
   "source": [
    "## Environment Setup (Google Drive Mounting)\n",
    "\n",
    "If running this notebook on Google Colab, you'll need to mount your Google Drive to access files stored there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12023,
     "status": "ok",
     "timestamp": 1620895963505,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "kR6XxREL1UJy",
    "outputId": "771b40f5-7a95-46a1-de61-9ac9c7b12dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef86de",
   "metadata": {},
   "source": [
    "## Data Directory Check\n",
    "\n",
    "This cell lists the content of the data directory to ensure that all necessary files are present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7493,
     "status": "ok",
     "timestamp": 1620895958954,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "Iv3KMGqH4P8e",
    "outputId": "0517d7c7-a084-4765-f7be-d0c043717a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " claim.png\n",
      " preprocess_data.ipynb\n",
      " preprocessing.py\n",
      " project_data\n",
      " __pycache__\n",
      " test_bert.ipynb\n",
      " test.ipynb\n",
      "'test_roberta - Copy.ipynb'\n",
      " test_roberta.ipynb\n",
      " train_bert.ipynb\n",
      " train.ipynb\n",
      " train_roberta.ipynb\n",
      " twitter-rumour-classification_roberta_512_batch16_grad1\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/JH_NLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 2067,
     "status": "ok",
     "timestamp": 1620902440878,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "GhZ5mt4l1GhC"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/JH_NLP')\n",
    "import pandas as pd\n",
    "from transformers import RobertaConfig, RobertaForSequenceClassification, RobertaTokenizerFast, Trainer, TrainingArguments\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from preprocessing import preprocess_data, get_dataset_and_labels\n",
    "from preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 33331,
     "status": "ok",
     "timestamp": 1620895984818,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "vw4_zeMM1GhK"
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 512\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', max_length = max_sequence_length)\n",
    "model = RobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/JH_NLP/twitter-rumour-classification_roberta_512_batch16_grad1/', local_files_only=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 33328,
     "status": "ok",
     "timestamp": 1620895984820,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "ZtT1yty71GhL"
   },
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label == \"rumour\":\n",
    "        return 1\n",
    "    elif label == \"non-rumour\":\n",
    "        return 0\n",
    "    else:\n",
    "        raise Exception(\"label classes must be 'rumour' or 'non-rumour'\")\n",
    "\n",
    "\n",
    "def convert_label_to_rumour(label):\n",
    "    if label == 1:\n",
    "        return \"rumour\"\n",
    "    elif label == 0:\n",
    "        return \"non-rumour\"\n",
    "    else:\n",
    "        raise Exception(\"label classes must be 1 or 0\")\n",
    "\n",
    "\n",
    "def get_labels(label_path, sourceIds):\n",
    "    with open(label_path) as f:\n",
    "        labels = json.load(f)\n",
    "    corresponding_labels = [labels[id] for id in sourceIds]\n",
    "    numeric_labels = [convert_label(label) for label in corresponding_labels]\n",
    "\n",
    "    return numeric_labels\n",
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.tokenized_texts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 131039,
     "status": "ok",
     "timestamp": 1620896082548,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "FVLKD4m-1GhM"
   },
   "outputs": [],
   "source": [
    "covid_path = \"/content/drive/MyDrive/JH_NLP/project_data/covid.data.jsonl\"\n",
    "test_texts, sourceIds = preprocess_data(data_path=covid_path, max_sequence_length=max_sequence_length)\n",
    "test_encodings = tokenizer(test_texts, padding = 'max_length', truncation=True, max_length = max_sequence_length)\n",
    "\n",
    "# Initiate a TestDataset object\n",
    "test_dataset = TestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1259957,
     "status": "ok",
     "timestamp": 1620897211480,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "7gGWsMkI1GhN",
    "outputId": "8aab4933-d596-4ac7-ffd3-b30783525600"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2183/2183 [18:27<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "label_ids: torch.Tensor = None\n",
    "preds: torch.Tensor = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "\n",
    "        batch['input_ids'] = batch['input_ids'].cuda()\n",
    "            \n",
    "        predictions = model(input_ids=batch['input_ids']\n",
    "                                   )\n",
    "        \n",
    "        predictions = predictions[0]\n",
    "\n",
    "        if preds is None:\n",
    "            preds = predictions.detach().sigmoid()\n",
    "        else:\n",
    "            preds = torch.cat((preds, predictions.detach()), dim=0)\n",
    "\n",
    "\n",
    "        # if label_ids is None:\n",
    "        #     label_ids = batch[\"labels\"].detach()\n",
    "        # else:\n",
    "        #     label_ids = torch.cat((label_ids, batch[\"labels\"].detach()), dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1259957,
     "status": "ok",
     "timestamp": 1620897211482,
     "user": {
      "displayName": "Jin Hong YONG",
      "photoUrl": "",
      "userId": "00816447813681998837"
     },
     "user_tz": -480
    },
    "id": "6odtQVab1GhO"
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(preds.to(\"cpu\"), axis=1)\n",
    "predictions_dict = {sourceId: convert_label_to_rumour(prediction) for sourceId, prediction in zip(sourceIds, predictions)}\n",
    "with open(\"/content/drive/MyDrive/JH_NLP/covid-output.json\", \"w\") as outputfile:\n",
    "    json.dump(predictions_dict, outputfile)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "get_covid_preds.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "f002c33ec35ee3433a40f1e373ee3a5b206853af00c8fa71f8a37a725600fbf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
